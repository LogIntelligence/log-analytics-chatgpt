,EventTemplate,Occurrences
0,Created MRAppMaster for application {app},1
1,Executing with tokens:,1
2,"Kind: {kind}, Service: {service}, Ident: (appAttemptId { application_id { id: {id} cluster_timestamp: {timestamp} } attemptId: {attempt} } keyId: {keyId})",1
3,Using mapred {committer}.,1
4,OutputCommitter set in config {config},1
5,OutputCommitter is {committer},1
6,Registering class {class1} for class {class2},6
7,Registering class {class} for class {class},2
8,Registering class {class} for class {handler},1
9,Default file system [{filesystem}],3
10,Emitting job history data to the timeline server is not enabled,1
11,loaded properties from {file},1
12,Scheduled snapshot period at {seconds} second(s).,1
13,MRAppMaster metrics system started,1
14,Adding job token for {job} to jobTokenSecretManager,1
15,Not uberizing {job} because: {reason},1
16,Input size for job {job_id} = {size}. Number of splits = {num_splits},1
17,Number of reduces for job {job_id} = {count},1
18,job_{job_id}Job Transitioned from {old_state} to {new_state},1
19,"MRAppMaster launching normal, non-uberized, multi-container job {job_id}.",1
20,Using callQueue class {class},2
21,Starting Socket Reader #{number} for port {port},2
22,Adding protocol {protocol} to the server,1
23,Instantiated MRClientService at {server},1
24,IPC Server Responder: starting,2
25,IPC Server listener on {port}: {status},2
26,Logging to {logger}(org.{package}) via {adapter},1
27,Http request log for {url} is not defined,1
28,Added global filter '{filterName}' (class={className}),1
29,Added filter {filterName} (class={className}) to context {context},1
30,Added filter {filterName} (class={className}) to context static,1
31,adding path spec: {path},2
32,Jetty bound to port {port},1
33,{server},1
34,Extract jar:{path} to {destination},1
35,Started HttpServer2$SelectChannelConnectorWithSafeStartup@{ip}:{port},1
36,Web app /mapreduce started at {time},1
37,Registered webapp guice modules,1
38,JOB_CREATE {job_id},1
39,nodeBlacklistingEnabled:{bool},1
40,maxTaskFailuresPerNode is {int},1
41,blacklistDisablePercent is {int},1
42,Connecting to ResourceManager at {server},1
43,"maxContainerCapability: <memory:{memory}, vCores:{core}>",1
44,queue: {queue},1
45,Upper limit on the thread pool size is {limit},1
46,yarn.client.max-cached-nodemanagers-proxies : {int},1
47,job_{job_id}Job Transitioned from {from_state} to {to_state},2
48,Processing the event EventType: {event},3
49,Resolved {server} to {location},33
50,task_{timestamp}_{id}_{type} Task Transitioned from {from} to {to},3
51,task_{timestamp}_m_{task_id} Task Transitioned from {old_state} to {new_state},4
52,task_{appId}_{attemptId}_{taskType}_{taskNumber} Task Transitioned from {oldState} to {newState},2
53,task_{timestamp}_m_{taskNumber} Task Transitioned from {oldState} to {newState},1
54,task_{appId}_{attemptId}_{taskType}_{taskIndex} Task Transitioned from {oldState} to {newState},1
55,{task} TaskAttempt Transitioned from NEW to UNASSIGNED,13
56,{task} TaskAttempt Transitioned from {state1} to {state2},5
57,"mapResourceRequest:<memory:{memory}, vCores:{cores}>",1
58,"Event Writer setup for JobId: {jobId}, File: {file}",1
59,"reduceResourceRequest:<memory:{memory}, vCores:{cores}>",1
60,Before Scheduling: PendingReds:{int} ScheduledMaps:{int} ScheduledReds:{int} AssignedMaps:{int} AssignedReds:{int} CompletedMaps:{int} CompletedReds:{int} ContAlloc:{int} ContRel:{int} HostLocal:{int} RackLocal:{int},5
61,"getResources() for {application}: ask={ask} release={release} newContainers={new} finishedContainers={finished} resourcelimit=<memory:{memory}, vCores:{core}> knownNMs={known}",7
62,"Recalculating schedule, headroom=<memory:{memory}, vCores:{core}>",131
63,Reduce slow start threshold not met. completedMapsForReduceSlowstart {int},54
64,Got allocated containers {count},10
65,Resolved {hostname} to {ip},6
66,Assigned container {container} to {attempt},3
67,Reduce slow start threshold not met. completedMapsForReduceSlowstart {count},76
68,After Scheduling: PendingReds:{int} ScheduledMaps:{int} ScheduledReds:{int} AssignedMaps:{int} AssignedReds:{int} CompletedMaps:{int} CompletedReds:{int} ContAlloc:{int} ContRel:{int} HostLocal:{int} RackLocal:{int},12
69,The job-jar file on the remote FS is {path},1
70,The job-conf file on the remote FS is {path},1
71,Adding #{num_tokens} tokens and #{num_keys} secret keys for NM use for launching container,1
72,Size of containertokens_dob is {int},1
73,Putting shuffle token in {data},1
74,{task} TaskAttempt Transitioned from UNASSIGNED to ASSIGNED,10
75,Processing the event EventType: {event} for container {container} taskAttempt {task},13
76,Launching {task},10
77,Opening proxy : {server}:{port},9
78,Shuffle port returned by ContainerManager for {task} : {port},9
79,TaskAttempt: [attempt_{number}_m_{mapper}_0] using containerId: [container_{number}_{mapper}_01_{attempt} on NM: [{server}:{port}],1
80,{task} TaskAttempt Transitioned from ASSIGNED to RUNNING,10
81,ATTEMPT_START {task},10
82,task_{timestamp}_{id}_{type}_{attempt} Task Transitioned from {fromState} to {toState},3
83,"getResources() for {application}: ask={ask} release={release} newContainers={new} finishedContainers={finished} resourcelimit=<memory:{memory}, vCores:{cores}> knownNMs={NMs}",1
84,Opening proxy : {proxy},4
85,TaskAttempt: [attempt_{number}_m_{mapper}_0] using containerId: [container_{number}_01_00000{attempt} on NM: [{server}:{port}],1
86,task_{appId}_{attemptId}_{taskType}_{taskNumber} Task Transitioned from {fromState} to {toState},4
87,Assigned container {container} to {task},7
88,TaskAttempt: [attempt_{number}_m_{mapper}_0] using containerId: [container_{number}_01_{attempt}_on NM: [{server}:{port}],2
89,{task} Task Transitioned from {from} to {to},3
90,Auth successful for {job} (auth:{auth}),10
91,JVM with ID : {jvm} asked for a task,10
92,JVM with ID: {jvm_id} given task: {task},4
93,JVM with ID: {jvm} given task: {task},6
94,Progress of TaskAttempt {task} is : {progress},289
95,TaskAttempt: [attempt_{number}_{number}_{type}_{id}] using containerId: [{container} on NM: [{server}:{port}],1
96,TaskAttempt: [attempt_{number}_m_{mapper}_0] using containerId: [container_{number}_{mapper}_01_{reducer} on NM: [{server}:{port}],5
97,Shuffle port returned by ContainerManager for {attempt} : {port},1
98,"getResources() for {application}: ask={ask} release={release} newContainers={new} finishedContainers={finished} resourcelimit=<memory:{memory}, vCores:{core}> knownNMs={NMs}",4
99,"Cannot assign container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: {resource}, Priority: {priority}, Token: Token { kind: ContainerToken, service: {service} }, ] for a map as either container memory less than required {required_memory} or no pending map tasks - maps.isEmpty={maps_is_empty}",1
100,Received completed container {container},2
101,Container complete event for unknown container id {container_id},1
102,Done acknowledgement from {task},1
103,{task} TaskAttempt Transitioned from RUNNING to {status},1
104,KILLING {task},3
105,attempt_{timestamp}_{id}_{type}_{attempt} TaskAttempt Transitioned from {from} to {to},1
106,Task succeeded with attempt {task},1
107,task_{timestamp}_{id}_{type}_{attempt} Task Transitioned from {from} to {to},1
108,Num completed Tasks: {count},1
109,Reduce slow start threshold reached. Scheduling reduces.,1
110,All maps assigned. Ramping up all remaining reduces:{int},1
111,DefaultSpeculator.addSpeculativeAttempt -- we are speculating {task},1
112,We launched {count} speculations. Sleeping {time} milliseconds.,1
113,Scheduling a redundant attempt for task {task},1
114,Diagnostics report from {task}: {reason}.,1
115,Address change detected. Old: {oldAddress} New: {newAddress},476
116,Failed to renew lease for [{client}] for {time} seconds. Will retry shortly ...,72
117,Failed to renew lease for [{client}] for {seconds} seconds. Will retry shortly ...,254
118,"Slow ReadProcessor read fields took {time}ms (threshold={threshold}ms); ack: seqno: {seqno} status: {status} status: {status} downstreamAckTimeNanos: {timeNanos}, targets: [{targets}]",1
119,DFSOutputStream ResponseProcessor exception for block {block},1
120,Error Recovery for block {block} in pipeline {pipeline}: bad datanode {datanode},1
121,DataStreamer Exception,1
122,ERROR IN CONTACTING RM.,147
123,"Retrying connect to server: {server}. Already tried {count} time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries={count}, sleepTime={count} MILLISECONDS)",146
124,Task: {attempt} - exited : {exception}: {message}; For more details see: {link},2
125,Diagnostics report from {task}: Error: {error}; For more details see: {link},2
126,Task cleanup failed for attempt {task},2
127,{task} TaskAttempt Transitioned from {from} to {to},2
128,Error writing History Event: {event},1
129,"Thread Thread[{threadName},{threadPriority},{threadGroup}] threw an Exception.",1
130,{count} failures on node {node},2
131,Added {task} to list of failed maps,2
132,Diagnostics report from {attempt}: Error: {error}: {details}; For more details see: {link},2
